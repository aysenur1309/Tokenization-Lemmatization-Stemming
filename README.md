# NLP ile Metin Ã–n Ä°ÅŸleme (Tokenization, Stemming, Lemmatization)

Bu proje, **DoÄŸal Dil Ä°ÅŸleme (Natural Language Processing - NLP)** alanÄ±nda yaygÄ±n olarak kullanÄ±lan **Tokenization**, **Stopwords Removal**, **Stemming** ve **Lemmatization** iÅŸlemlerini hem **Ä°ngilizce** hem de **TÃ¼rkÃ§e** metinler Ã¼zerinde uygulamaktadÄ±r.

---

## Ã–zellikler

- **Tokenization:** Metni anlamlÄ± kelime parÃ§alarÄ±na ayÄ±rma.
- **Stopwords Removal:** Anlam taÅŸÄ±mayan kelimeleri (Ã¶rn. "ve", "ile", "the", "is") temizleme.
- **Stemming:** Kelimeleri kÃ¶k hÃ¢line indirme (Ã¶r. `running â†’ run`).
- **Lemmatization:** Kelimeleri sÃ¶zlÃ¼kteki temel hÃ¢line dÃ¶nÃ¼ÅŸtÃ¼rme (Ã¶r. `better â†’ good`).
- **TÃ¼rkÃ§e & Ä°ngilizce desteÄŸi:** `nltk` ve `snowballstemmer` kullanÄ±larak.

---

## ğŸ›  KullanÄ±lan KÃ¼tÃ¼phaneler

- **nltk** â†’ Tokenization, stopwords, stemming, lemmatization
- **snowballstemmer** â†’ TÃ¼rkÃ§e kÃ¶k Ã§Ä±karma
- **string** â†’ Noktalama iÅŸaretlerini temizleme

---

## Kurulum:
```bash
pip install nltk snowballstemmer
